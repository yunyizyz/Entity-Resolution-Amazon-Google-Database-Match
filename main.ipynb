{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becff103",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72d162",
   "metadata": {},
   "source": [
    "Yunyi Zhang<BR>\n",
    "USC ID: 7518630167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5592d3",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "In this assignment, you'll work with the Amazon-Google product dataset to perform entity resolution. Your task is to identify and match records across the Amazon and Google product datasets that refer to the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b805e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import product\n",
    "from numpy.linalg import norm\n",
    "from collections import defaultdict\n",
    "from Levenshtein import distance as lev\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b615ba",
   "metadata": {},
   "source": [
    "### Dataset: \n",
    "You'll use these files for this assignment:\n",
    "- Amazon.csv\n",
    "- Google.csv\n",
    "- Amazon_GoogleProducts_perfectMapping.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ebfa0",
   "metadata": {},
   "source": [
    "### Question 1: Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69163a",
   "metadata": {},
   "source": [
    "**1.1 [10 points]** : Load the three files using Pandas. How many unique products are there in (i) Amazon, and (ii) Google? (Hint: you will have to use the ground-truth links in the perfectMapping file to properly answer this question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544400b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('./Amazon-GoogleProducts/Amazon-GoogleProducts/Amazon.csv', encoding='unicode_escape', names = ['id','name','description','manufacturer','price'], header=0)\n",
    "google = pd.read_csv('./Amazon-GoogleProducts/Amazon-GoogleProducts/GoogleProducts.csv', encoding='unicode_escape')\n",
    "perfect_match = pd.read_csv('./Amazon-GoogleProducts/Amazon-GoogleProducts/Amzon_GoogleProducts_perfectMapping.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73127b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon.fillna(value=\" \", inplace=True)\n",
    "google.fillna(value=\" \",inplace=True)\n",
    "perfect_match.fillna(value=\" \",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c066273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000jz4hqo</td>\n",
       "      <td>clickart 950 000 - premier image pack (dvd-rom)</td>\n",
       "      <td></td>\n",
       "      <td>broderbund</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0006zf55o</td>\n",
       "      <td>ca international - arcserve lap/desktop oem 30pk</td>\n",
       "      <td>oem arcserve backup v11.1 win 30u for laptops ...</td>\n",
       "      <td>computer associates</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td></td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b000g80lqo</td>\n",
       "      <td>peachtree by sage premium accounting for nonpr...</td>\n",
       "      <td>peachtree premium accounting for nonprofits 20...</td>\n",
       "      <td>sage software</td>\n",
       "      <td>599.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0006se5bq</td>\n",
       "      <td>singing coach unlimited</td>\n",
       "      <td>singing coach unlimited - electronic learning ...</td>\n",
       "      <td>carry-a-tune technologies</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000ehpzv8</td>\n",
       "      <td>emc retrospect 7.5 disk to disk windows</td>\n",
       "      <td>emc retrospect 7.5 disk to diskcromwindows</td>\n",
       "      <td>dantz</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b00021xhzw</td>\n",
       "      <td>adobe after effects professional 6.5 upgrade f...</td>\n",
       "      <td>upgrade only; installation of after effects st...</td>\n",
       "      <td>adobe</td>\n",
       "      <td>499.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b000gzwjgc</td>\n",
       "      <td>acad upgrade dragon naturallyspeaking pro solu...</td>\n",
       "      <td>- marketing information: dragon naturallyspeak...</td>\n",
       "      <td>nuance academic</td>\n",
       "      <td>399.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0000dbykm</td>\n",
       "      <td>mia's math adventure: just in time</td>\n",
       "      <td>in mia's math adventure: just in time children...</td>\n",
       "      <td>kutoka</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b00029bqa2</td>\n",
       "      <td>disney's 1st &amp; 2nd grade bundle (pixar 1st gra...</td>\n",
       "      <td>disney's 1st &amp; 2nd grade bundle will help your...</td>\n",
       "      <td>disney</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               name  \\\n",
       "0  b000jz4hqo    clickart 950 000 - premier image pack (dvd-rom)   \n",
       "1  b0006zf55o   ca international - arcserve lap/desktop oem 30pk   \n",
       "2  b00004tkvy   noah's ark activity center (jewel case ages 3-8)   \n",
       "3  b000g80lqo  peachtree by sage premium accounting for nonpr...   \n",
       "4  b0006se5bq                            singing coach unlimited   \n",
       "5  b000ehpzv8            emc retrospect 7.5 disk to disk windows   \n",
       "6  b00021xhzw  adobe after effects professional 6.5 upgrade f...   \n",
       "7  b000gzwjgc  acad upgrade dragon naturallyspeaking pro solu...   \n",
       "8  b0000dbykm                 mia's math adventure: just in time   \n",
       "9  b00029bqa2  disney's 1st & 2nd grade bundle (pixar 1st gra...   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1  oem arcserve backup v11.1 win 30u for laptops ...   \n",
       "2                                                      \n",
       "3  peachtree premium accounting for nonprofits 20...   \n",
       "4  singing coach unlimited - electronic learning ...   \n",
       "5         emc retrospect 7.5 disk to diskcromwindows   \n",
       "6  upgrade only; installation of after effects st...   \n",
       "7  - marketing information: dragon naturallyspeak...   \n",
       "8  in mia's math adventure: just in time children...   \n",
       "9  disney's 1st & 2nd grade bundle will help your...   \n",
       "\n",
       "                manufacturer   price  \n",
       "0                 broderbund    0.00  \n",
       "1        computer associates    0.00  \n",
       "2         victory multimedia    0.00  \n",
       "3              sage software  599.99  \n",
       "4  carry-a-tune technologies   99.99  \n",
       "5                      dantz    0.00  \n",
       "6                      adobe  499.99  \n",
       "7            nuance academic  399.54  \n",
       "8                     kutoka   19.99  \n",
       "9                     disney   14.99  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c22458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1363 entries, 0 to 1362\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            1363 non-null   object \n",
      " 1   name          1363 non-null   object \n",
      " 2   description   1363 non-null   object \n",
      " 3   manufacturer  1363 non-null   object \n",
      " 4   price         1363 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "amazon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8eb3a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1112...</td>\n",
       "      <td>learning quickbooks 2007</td>\n",
       "      <td>learning quickbooks 2007</td>\n",
       "      <td>intuit</td>\n",
       "      <td>38.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1153...</td>\n",
       "      <td>superstart! fun with reading &amp; writing!</td>\n",
       "      <td>fun with reading &amp; writing! is designed to hel...</td>\n",
       "      <td></td>\n",
       "      <td>8.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1134...</td>\n",
       "      <td>qb pos 6.0 basic software</td>\n",
       "      <td>qb pos 6.0 basic retail mngmt software. for re...</td>\n",
       "      <td>intuit</td>\n",
       "      <td>637.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1204...</td>\n",
       "      <td>math missions: the amazing arcade adventure (g...</td>\n",
       "      <td>save spectacle city by disrupting randall unde...</td>\n",
       "      <td></td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1224...</td>\n",
       "      <td>production prem cs3 mac upgrad</td>\n",
       "      <td>adobe cs3 production premium mac upgrade from ...</td>\n",
       "      <td>adobe software</td>\n",
       "      <td>805.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1487...</td>\n",
       "      <td>jumpstart(r) advanced 1st grade</td>\n",
       "      <td>prepare your child for the 1st grade and beyon...</td>\n",
       "      <td></td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1491...</td>\n",
       "      <td>ibm(r) viavoice(r) advanced edition 10</td>\n",
       "      <td>ibm viavoice advanced edition release 10 is a ...</td>\n",
       "      <td></td>\n",
       "      <td>78.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1497...</td>\n",
       "      <td>xbox 360: gears of war</td>\n",
       "      <td>as marcus fenix you fight a war against the im...</td>\n",
       "      <td></td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1498...</td>\n",
       "      <td>documents to go premium 7.0</td>\n",
       "      <td>this pda software enables you to use your docu...</td>\n",
       "      <td></td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1499...</td>\n",
       "      <td>microsoft(r) picture it! digital image pro 9.0</td>\n",
       "      <td>picture it! digital image pro puts you in cont...</td>\n",
       "      <td></td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3226 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     http://www.google.com/base/feeds/snippets/1112...   \n",
       "1     http://www.google.com/base/feeds/snippets/1153...   \n",
       "2     http://www.google.com/base/feeds/snippets/1134...   \n",
       "3     http://www.google.com/base/feeds/snippets/1204...   \n",
       "4     http://www.google.com/base/feeds/snippets/1224...   \n",
       "...                                                 ...   \n",
       "3221  http://www.google.com/base/feeds/snippets/1487...   \n",
       "3222  http://www.google.com/base/feeds/snippets/1491...   \n",
       "3223  http://www.google.com/base/feeds/snippets/1497...   \n",
       "3224  http://www.google.com/base/feeds/snippets/1498...   \n",
       "3225  http://www.google.com/base/feeds/snippets/1499...   \n",
       "\n",
       "                                                   name  \\\n",
       "0                              learning quickbooks 2007   \n",
       "1               superstart! fun with reading & writing!   \n",
       "2                             qb pos 6.0 basic software   \n",
       "3     math missions: the amazing arcade adventure (g...   \n",
       "4                        production prem cs3 mac upgrad   \n",
       "...                                                 ...   \n",
       "3221                    jumpstart(r) advanced 1st grade   \n",
       "3222             ibm(r) viavoice(r) advanced edition 10   \n",
       "3223                             xbox 360: gears of war   \n",
       "3224                        documents to go premium 7.0   \n",
       "3225     microsoft(r) picture it! digital image pro 9.0   \n",
       "\n",
       "                                            description    manufacturer  \\\n",
       "0                              learning quickbooks 2007          intuit   \n",
       "1     fun with reading & writing! is designed to hel...                   \n",
       "2     qb pos 6.0 basic retail mngmt software. for re...          intuit   \n",
       "3     save spectacle city by disrupting randall unde...                   \n",
       "4     adobe cs3 production premium mac upgrade from ...  adobe software   \n",
       "...                                                 ...             ...   \n",
       "3221  prepare your child for the 1st grade and beyon...                   \n",
       "3222  ibm viavoice advanced edition release 10 is a ...                   \n",
       "3223  as marcus fenix you fight a war against the im...                   \n",
       "3224  this pda software enables you to use your docu...                   \n",
       "3225  picture it! digital image pro puts you in cont...                   \n",
       "\n",
       "       price  \n",
       "0      38.99  \n",
       "1       8.49  \n",
       "2     637.99  \n",
       "3      12.95  \n",
       "4     805.99  \n",
       "...      ...  \n",
       "3221   19.99  \n",
       "3222   78.95  \n",
       "3223   59.99  \n",
       "3224   49.99  \n",
       "3225   99.87  \n",
       "\n",
       "[3226 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a72909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3226 entries, 0 to 3225\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            3226 non-null   object\n",
      " 1   name          3226 non-null   object\n",
      " 2   description   3226 non-null   object\n",
      " 3   manufacturer  3226 non-null   object\n",
      " 4   price         3226 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 126.1+ KB\n"
     ]
    }
   ],
   "source": [
    "google.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a56c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idAmazon</th>\n",
       "      <th>idGoogleBase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000jz4hqo</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b000g80lqo</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0006se5bq</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1842...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b00021xhzw</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>b00005bigp</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>b000h1df7w</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>b000p9cr66</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>b000p9cr66</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>b000j588g4</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1773...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idAmazon                                       idGoogleBase\n",
       "0     b000jz4hqo  http://www.google.com/base/feeds/snippets/1844...\n",
       "1     b00004tkvy  http://www.google.com/base/feeds/snippets/1844...\n",
       "2     b000g80lqo  http://www.google.com/base/feeds/snippets/1844...\n",
       "3     b0006se5bq  http://www.google.com/base/feeds/snippets/1842...\n",
       "4     b00021xhzw  http://www.google.com/base/feeds/snippets/1843...\n",
       "...          ...                                                ...\n",
       "1295  b00005bigp  http://www.google.com/base/feeds/snippets/1773...\n",
       "1296  b000h1df7w  http://www.google.com/base/feeds/snippets/1773...\n",
       "1297  b000p9cr66  http://www.google.com/base/feeds/snippets/1772...\n",
       "1298  b000p9cr66  http://www.google.com/base/feeds/snippets/1321...\n",
       "1299  b000j588g4  http://www.google.com/base/feeds/snippets/1773...\n",
       "\n",
       "[1300 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eee4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1363 unique values in Amazon.\n"
     ]
    }
   ],
   "source": [
    "unique_a=len(pd.unique(amazon['id']))\n",
    "print(f'There are {unique_a} unique values in Amazon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c09f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3226 unique values in Google.\n"
     ]
    }
   ],
   "source": [
    "unique_g=len(pd.unique(google['id']))\n",
    "print(f'There are {unique_g} unique values in Google.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d08ab",
   "metadata": {},
   "source": [
    "**1.2 [15 points]**: Now, perform text preprocessing on the 'name', 'description', and 'manufacturer’ columns from both the Amazon and Google products datasets. Make sure to do the following preprocessing tasks:\n",
    "- Convert all characters to lowercase.\n",
    "- Remove special characters and punctuation, e.g., comma, parentheses, etc.\n",
    "- Eliminate stop words, e.g.,”the”, “an”, “a”, etc.\n",
    "- Convert empty strings and 'null' entries to actual null values.\n",
    "\n",
    "\n",
    "After cleaning the text data, add three new columns to both of the dataframes: 'name_cleaned', 'description_cleaned', and 'manufacturer_cleaned'. These columns store the processed text.\n",
    "\n",
    "\n",
    "(Although the following feature engineering processes are performed on the “cleaned” versions of the columns, it is always a good habit to not alter the original column, as it could be useful for spot-checks for your subsequent steps!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebb3645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    processed_text = text.str.lower()\n",
    "    #This is for question 2\n",
    "    tokened_text = text.str.lower()\n",
    "\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    for i in range(len(processed_text)):\n",
    "        tokens = word_tokenize(processed_text[i])\n",
    "        tokens = [word for word in tokens if (word.isalpha() or word.isnumeric()) and word.isascii() and word not in english_stopwords]\n",
    "        processed_text[i] = ' '.join(tokens)\n",
    "        tokened_text[i] = tokens\n",
    "\n",
    "    return processed_text, tokened_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0e26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['name', 'description', 'manufacturer']:\n",
    "    google[column + '_cleaned'], google[column + '_tokened'] = preprocess_text(google[column])\n",
    "    amazon[column + '_cleaned'], amazon[column + '_tokened'] = preprocess_text(amazon[column])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36e66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_text(text):\n",
    "    tokened_text = copy(text)\n",
    "    for i in range(len(text)):\n",
    "        tokens = word_tokenize(tokened_text[i])\n",
    "        tokens = [word for word in tokens]\n",
    "        tokened_text[i] = tokens\n",
    "\n",
    "    return tokened_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2dcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "google['tokened_name_raw'] = token_text(google['name'])\n",
    "amazon['tokened_name_raw'] = token_text(amazon['name'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c51f45",
   "metadata": {},
   "source": [
    "**1.3 [10 points]**: Apply TF-IDF transformations to the 'name_cleaned', 'description_cleaned', and 'manufacturer_cleaned' fields of both datasets. Append the resulting TF-IDF vectors to the respective datasets as new columns: 'name_tfidf', 'description_tfidf', and ‘manufacturer_tfidf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0371ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_transform(df, column):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = np.array(vectorizer.fit_transform(df[column]).todense())\n",
    "    matrix = [X[i] for i in range(X.shape[0])]\n",
    "    tfidf = pd.Series(matrix, name='tfidf')\n",
    "\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df06394",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_joined_df = pd.concat([google, amazon], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0db456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = np.array(vectorizer.fit_transform(full_joined_df.iloc[:2,5]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab0bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['name_cleaned', 'description_cleaned', 'manufacturer_cleaned']:\n",
    "    full_joined_df[column + '_tfidf'] = tfidf_transform(full_joined_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de687ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "google = full_joined_df.iloc[:3226,:]\n",
    "amazon = full_joined_df.iloc[3226:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be817b4",
   "metadata": {},
   "source": [
    "### Question 2: Simple Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42267f75",
   "metadata": {},
   "source": [
    "In this section, you will implement and apply various blocking techniques to efficiently identify potential matches between the Amazon and Google product datasets. Blocking reduces the comparison space by only comparing records that share certain characteristics, making the entity resolution process more scalable. Implement the following blocking strategies:\n",
    "\n",
    "\n",
    "* Manufacturer Blocking: Create blocks of records that share the same manufacturer (i.e., where the records share the **exact string** value in the **manufacturer_cleaned** field). This blocking ensures that only records within each block, indicating they're from the same manufacturer, are to be compared with each other.\n",
    "\n",
    "\n",
    "* Name Token Blocking: First, **tokenize** the 'name_cleaned' fields of the records in both datasets. Records are considered to be in the same block if they share **any common token** in their 'name' field. Consider these common tokens as the match key values that identify records belonging to the same block.\n",
    "\n",
    "\n",
    "* Description Token Blocking: **Tokenize** the 'description_cleaned' fields of the records. Consider records as part of the same block if they share **any token** in their 'description_cleaned'. \n",
    "\n",
    "\n",
    "**2.1 [20 points]** As constraints,  1) discard any blocks that contain more than 50 records, and 2) delete any blocks that have no record from either one of the two dataset,, as a match requires at least a pair of records between the dataset. For the questions below, consider the collection of all the blocks generated from the above all three strategies, and answer the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35f1f9",
   "metadata": {},
   "source": [
    "### *The tokenized codes were included in Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a854810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google: (3226, 15)\n",
      "Amazon: (1363, 15)\n",
      "Full: (4589, 15)\n"
     ]
    }
   ],
   "source": [
    "full_joined_df = pd.concat([google, amazon], ignore_index=True)\n",
    "print('Google: '+str(google.shape))\n",
    "print('Amazon: '+str(amazon.shape))\n",
    "print('Full: '+str(full_joined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27af5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturer_blocks = full_joined_df.groupby('manufacturer_cleaned').apply(lambda x: x.index.tolist()).tolist()\n",
    "manufacturer_blocks_constrained = [block for block in manufacturer_blocks if 1 <= len(block) <= 50\n",
    "                       and any(0 <= i <= 3225 for i in block) and any(3226 <= i <= 4589 for i in block)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361acff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blocks(tokenizeds, word_blocks):\n",
    "    \n",
    "    for i, the_list in enumerate(tokenizeds):\n",
    "        for word in the_list:\n",
    "            word_blocks[word].append(i)\n",
    "\n",
    "    the_blocks = list(word_blocks.values())\n",
    "\n",
    "    return the_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7f21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_names_cleaned = full_joined_df['name_tokened']\n",
    "word_blocks_name_cleaned = defaultdict(list)\n",
    "\n",
    "name_blocks_cleaned = create_blocks(tokenized_names_cleaned, word_blocks_name_cleaned)\n",
    "\n",
    "name_blocks_constrained_cleaned = [\n",
    "    block for block in name_blocks_cleaned if (\n",
    "        1 <= len(block) <= 50\n",
    "        and any(0 <= i <= 3225 for i in block)\n",
    "        and any(3226 <= i <= 4589 for i in block)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4721701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_descriptions = full_joined_df['description_tokened']\n",
    "word_blocks_description = defaultdict(list)\n",
    "\n",
    "description_blocks = create_blocks(tokenized_descriptions, word_blocks_description)\n",
    "\n",
    "description_blocks_constrained = [\n",
    "    block for block in description_blocks if (\n",
    "        1 <= len(block) <= 50\n",
    "        and any(0 <= i <= 3225 for i in block)\n",
    "        and any(3226 <= i <= 4589 for i in block)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d415f8",
   "metadata": {},
   "source": [
    "1. How many total blocks were created across all blocking strategies after discarding any blocks that do not satisfy the constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab64d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6401 blocks were created.\n"
     ]
    }
   ],
   "source": [
    "all_blocks = manufacturer_blocks_constrained + name_blocks_constrained_cleaned + description_blocks_constrained\n",
    "all_blocks_before_constrains = manufacturer_blocks + name_blocks_cleaned + description_blocks\n",
    "\n",
    "total_block = len(all_blocks)\n",
    "print(f'{total_block} blocks were created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae3c1f",
   "metadata": {},
   "source": [
    "2. How many unique Amazon products are included in all of the blocks after applying the constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9298e92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360 unique Amazon products are included.\n"
     ]
    }
   ],
   "source": [
    "unique_amazon_products = set(index for block in all_blocks for index in block if 3226 <= index <= 4589)\n",
    "print(f'{len(unique_amazon_products)} unique Amazon products are included.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f69717",
   "metadata": {},
   "source": [
    "3. What is the total number of blocks that only contain Amazon records across all blocking strategies before applying the constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc1468e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6174 blocks only contain Amazon records.\n"
     ]
    }
   ],
   "source": [
    "only_amazon_products = [block for block in all_blocks_before_constrains if all(3226 <= i <= 4589 for i in block)]\n",
    "print(f'{len(only_amazon_products)} blocks only contain Amazon records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813e128",
   "metadata": {},
   "source": [
    "4. What about  the total number of blocks that only contain Google records before applying the constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eccecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5443 blocks only contain Google records.\n"
     ]
    }
   ],
   "source": [
    "only_google_products = [block for block in all_blocks_before_constrains if all(0 <= i <= 3225 for i in block)]\n",
    "print(f'{len(only_google_products)} blocks only contain Google records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b35c0",
   "metadata": {},
   "source": [
    "### Question 3: Pairing and Similarity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbcf60",
   "metadata": {},
   "source": [
    "**3.1 [15 points]**: Now consider the blocks generated by ***Manufacturer Blocking***. Within each valid block, generate all possible pairings of records from the Amazon dataset with those from the Google dataset. This step creates a set of candidate pairs, each potentially representing the same product. Using the ground-truth file we imported earlier,\n",
    "\n",
    "\n",
    "1. What is the pairs completeness for the candidate pairs resulting from Manufacturer Blocking?\n",
    "2. What reduction ratio has been achieved through Manufacturer Blocking?\n",
    "3. Assuming perfect similarity, what will be the precision and recall rates for the overall ER system implementing Manufacturer Blocking strategy？\n",
    "\n",
    "\n",
    "* Note: This method is efficient as it limits comparisons to records already deemed potentially identical or similar through blocking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43ca410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacture_pairs = set()\n",
    "\n",
    "for block in manufacturer_blocks_constrained:\n",
    "    block_pairs = set(product([full_joined_df.iloc[i,0] for i in block if 3226 <= i <= 4589],[full_joined_df.iloc[i,0] for i in block if 0 <= i <= 3225]))\n",
    "    manufacture_pairs.update(block_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6277c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manufacture_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0057811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_pairs = set(zip(perfect_match['idAmazon'], perfect_match['idGoogleBase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b068717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs Completeness is: 0.03923076923076923\n"
     ]
    }
   ],
   "source": [
    "true_positive_pairs = manufacture_pairs.intersection(ground_truth_pairs)\n",
    "pairs_completeness = len(true_positive_pairs) / len(ground_truth_pairs)\n",
    "print(f\"Pairs Completeness is: {pairs_completeness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "135814eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df98ca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction Ratio: 0.9996691107624451\n",
      "Precision: 0.03502747252747253\n",
      "Recall: 0.03923076923076923\n"
     ]
    }
   ],
   "source": [
    "reduction_ratio = 1 - (len(manufacture_pairs) / (3226 * 1364))\n",
    "precision = len(true_positive_pairs) / len(manufacture_pairs)\n",
    "recall = len(true_positive_pairs) / len(ground_truth_pairs)\n",
    "\n",
    "print(f\"Reduction Ratio: {reduction_ratio}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfcb45",
   "metadata": {},
   "source": [
    "**3.2 [20 points]**: Consolidate the candidate pairs into a **new** single DataFrame referred to as \"candidate_pairs\". This DataFrame is intended to contain columns from the Amazon and Google datasets that correspond to each group of candidate pairs. Print the first 10 rows of \"candidate_pairs\".\n",
    "\n",
    "For each pair, your DataFrame should at least include the following columns:\n",
    "\n",
    "* 'amazon_id': The unique identifier for the product in the Amazon dataset.\n",
    "* 'google_id': The unique identifier for the product in the Google dataset.\n",
    "* 'amazon_name_tfidf': The name of the product from the Amazon dataset.\n",
    "* 'google_name_tfidf': The name of the product from the Google dataset.\n",
    "* 'amazon_description_tfidf': The description of the product from the Amazon dataset.\n",
    "* 'google_description_tfidf': The description of the product from the Google dataset.\n",
    "* 'amazon_manufacturer_tfidf': The manufacturer of the product from the Amazon dataset.\n",
    "* 'google_manufacturer_tfidf': The manufacturer of the product from the Google dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff2916c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>google_id</th>\n",
       "      <th>amazon_name_tfidf</th>\n",
       "      <th>google_name_tfidf</th>\n",
       "      <th>amazon_description_tfidf</th>\n",
       "      <th>google_description_tfidf</th>\n",
       "      <th>amazon_manufacturer_tfidf</th>\n",
       "      <th>google_manufacturer_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000fvqo0o</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/6247...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000cpshfs</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1299...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b00004ochj</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1494...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b000v7vz1u</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/4749...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b000i82j80</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/3306...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000bcgfe2</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/4036...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b000ayxld4</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1836...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b0009jlux8</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1795...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0006b6b1a</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1837...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b000hbvvg4</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1283...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                                          google_id  \\\n",
       "0  b000fvqo0o  http://www.google.com/base/feeds/snippets/6247...   \n",
       "1  b000cpshfs  http://www.google.com/base/feeds/snippets/1299...   \n",
       "2  b00004ochj  http://www.google.com/base/feeds/snippets/1494...   \n",
       "3  b000v7vz1u  http://www.google.com/base/feeds/snippets/4749...   \n",
       "4  b000i82j80  http://www.google.com/base/feeds/snippets/3306...   \n",
       "5  b000bcgfe2  http://www.google.com/base/feeds/snippets/4036...   \n",
       "6  b000ayxld4  http://www.google.com/base/feeds/snippets/1836...   \n",
       "7  b0009jlux8  http://www.google.com/base/feeds/snippets/1795...   \n",
       "8  b0006b6b1a  http://www.google.com/base/feeds/snippets/1837...   \n",
       "9  b000hbvvg4  http://www.google.com/base/feeds/snippets/1283...   \n",
       "\n",
       "                                   amazon_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                   google_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            amazon_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            google_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           amazon_manufacturer_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           google_manufacturer_tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = []\n",
    "\n",
    "for amazon_id, google_id in manufacture_pairs:\n",
    "    amazon_line = pd.DataFrame(amazon[amazon['id']==amazon_id])\n",
    "    google_line = pd.DataFrame(google[google['id']==google_id])\n",
    "\n",
    "    pair_data = {\n",
    "        'amazon_id': amazon_line.iloc[0,0],\n",
    "        'google_id': google_line.iloc[0,0],\n",
    "        'amazon_name_tfidf': amazon_line.iloc[0,12],\n",
    "        'google_name_tfidf': google_line.iloc[0,12],\n",
    "        'amazon_description_tfidf': amazon_line.iloc[0,13],\n",
    "        'google_description_tfidf': google_line.iloc[0,13],\n",
    "        'amazon_manufacturer_tfidf': amazon_line.iloc[0,14],\n",
    "        'google_manufacturer_tfidf': google_line.iloc[0,14]\n",
    "    }\n",
    "\n",
    "    candidate_pairs.append(pair_data)\n",
    "\n",
    "candidate_pairs_df = pd.DataFrame(candidate_pairs)\n",
    "candidate_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4284fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1456 entries, 0 to 1455\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   amazon_id                  1456 non-null   object\n",
      " 1   google_id                  1456 non-null   object\n",
      " 2   amazon_name_tfidf          1456 non-null   object\n",
      " 3   google_name_tfidf          1456 non-null   object\n",
      " 4   amazon_description_tfidf   1456 non-null   object\n",
      " 5   google_description_tfidf   1456 non-null   object\n",
      " 6   amazon_manufacturer_tfidf  1456 non-null   object\n",
      " 7   google_manufacturer_tfidf  1456 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 91.1+ KB\n"
     ]
    }
   ],
   "source": [
    "candidate_pairs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb624311",
   "metadata": {},
   "source": [
    "**3.3 [10 points]**:Unfortunately, similarity functions are not perfect in practice. For the candidate set you computed in 3.1, calculate similarity scores for each candidate pair formed by: \n",
    "\n",
    "(i)  computing  the Cosine Similarity measure between each of the corresponding 'name_tfidf', 'description_tfidf', and 'manufacturer_tfidf' fields in the two records (leading to three cosine sim. scores); \n",
    "\n",
    "(ii)  average the three scores to yield a single composite ‘similarity’ score.\n",
    "\n",
    "\n",
    "Next, we must compute a ‘threshold’ in [0,1], such that for pairs with score >= the threshold, the pair is predicted to be a duplicate; otherwise, the pair is deemed to be a non-duplicate. Consider potential thresholds at increments of 0.1, starting from 0 and ending at 1. At what threshold(s) is the F-measure optimized, and what is the optimized F-measure?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e039d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\云忆\\AppData\\Local\\Temp\\ipykernel_9332\\2548815811.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  description_sim = np.dot(description_vector_amazon, description_vector_google) / (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>google_id</th>\n",
       "      <th>amazon_name_tfidf</th>\n",
       "      <th>google_name_tfidf</th>\n",
       "      <th>amazon_description_tfidf</th>\n",
       "      <th>google_description_tfidf</th>\n",
       "      <th>amazon_manufacturer_tfidf</th>\n",
       "      <th>google_manufacturer_tfidf</th>\n",
       "      <th>avg_similarity</th>\n",
       "      <th>name_similarity</th>\n",
       "      <th>description_similarity</th>\n",
       "      <th>manufacturer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000fvqo0o</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/6247...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.548717</td>\n",
       "      <td>0.472945</td>\n",
       "      <td>0.173206</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000cpshfs</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1299...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b00004ochj</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1494...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.490402</td>\n",
       "      <td>0.294114</td>\n",
       "      <td>0.177091</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b000v7vz1u</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/4749...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.372567</td>\n",
       "      <td>0.117702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b000i82j80</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/3306...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.504328</td>\n",
       "      <td>0.512984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000bcgfe2</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/4036...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.362374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b000ayxld4</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1836...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.362778</td>\n",
       "      <td>0.064323</td>\n",
       "      <td>0.024011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b0009jlux8</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1795...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0006b6b1a</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1837...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.624055</td>\n",
       "      <td>0.634602</td>\n",
       "      <td>0.237562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b000hbvvg4</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1283...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.372580</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                                          google_id  \\\n",
       "0  b000fvqo0o  http://www.google.com/base/feeds/snippets/6247...   \n",
       "1  b000cpshfs  http://www.google.com/base/feeds/snippets/1299...   \n",
       "2  b00004ochj  http://www.google.com/base/feeds/snippets/1494...   \n",
       "3  b000v7vz1u  http://www.google.com/base/feeds/snippets/4749...   \n",
       "4  b000i82j80  http://www.google.com/base/feeds/snippets/3306...   \n",
       "5  b000bcgfe2  http://www.google.com/base/feeds/snippets/4036...   \n",
       "6  b000ayxld4  http://www.google.com/base/feeds/snippets/1836...   \n",
       "7  b0009jlux8  http://www.google.com/base/feeds/snippets/1795...   \n",
       "8  b0006b6b1a  http://www.google.com/base/feeds/snippets/1837...   \n",
       "9  b000hbvvg4  http://www.google.com/base/feeds/snippets/1283...   \n",
       "\n",
       "                                   amazon_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                   google_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            amazon_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            google_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           amazon_manufacturer_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           google_manufacturer_tfidf  avg_similarity  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.548717   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.333333   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.490402   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.372567   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.504328   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.362374   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.362778   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.333333   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.624055   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.372580   \n",
       "\n",
       "   name_similarity  description_similarity  manufacturer_similarity  \n",
       "0         0.472945                0.173206                      1.0  \n",
       "1         0.000000                0.000000                      1.0  \n",
       "2         0.294114                0.177091                      1.0  \n",
       "3         0.117702                0.000000                      1.0  \n",
       "4         0.512984                0.000000                      1.0  \n",
       "5         0.000000                0.087123                      1.0  \n",
       "6         0.064323                0.024011                      1.0  \n",
       "7         0.000000                0.000000                      1.0  \n",
       "8         0.634602                0.237562                      1.0  \n",
       "9         0.064391                0.053348                      1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_similarities = []\n",
    "name_similarities = []\n",
    "description_similarities = []\n",
    "manufacturer_similarities = []\n",
    "\n",
    "for i in range(len(candidate_pairs_df)):\n",
    "    name_vector_amazon = candidate_pairs_df.iloc[i, 2]\n",
    "    name_vector_google = candidate_pairs_df.iloc[i, 3]\n",
    "\n",
    "    description_vector_amazon = candidate_pairs_df.iloc[i, 4]\n",
    "    description_vector_google = candidate_pairs_df.iloc[i, 5]\n",
    "\n",
    "    manufacturer_vector_amazon = candidate_pairs_df.iloc[i, 6]\n",
    "    manufacturer_vector_google = candidate_pairs_df.iloc[i, 7]\n",
    "\n",
    "    name_sim = np.dot(name_vector_amazon, name_vector_google) / (\n",
    "            norm(name_vector_amazon) * norm(name_vector_google))\n",
    "    \n",
    "    description_sim = np.dot(description_vector_amazon, description_vector_google) / (\n",
    "            norm(description_vector_amazon) * norm(description_vector_google))\n",
    "    \n",
    "    manufacturer_sim = np.dot(manufacturer_vector_amazon, manufacturer_vector_google) / (\n",
    "            norm(manufacturer_vector_amazon) * norm(manufacturer_vector_google))\n",
    "\n",
    "    name_sim = np.nan_to_num(name_sim, nan=0)\n",
    "    name_similarities.append(name_sim)\n",
    "\n",
    "    description_sim = np.nan_to_num(description_sim, nan=0)\n",
    "    description_similarities.append(description_sim)\n",
    "\n",
    "    manufacturer_sim = np.nan_to_num(manufacturer_sim, nan=0)\n",
    "    manufacturer_similarities.append(manufacturer_sim)\n",
    "\n",
    "    avg_similarity = np.mean([name_sim, description_sim, manufacturer_sim], axis=0)\n",
    "    avg_similarities.append(avg_similarity)\n",
    "\n",
    "candidate_pairs_df['avg_similarity'] = avg_similarities\n",
    "candidate_pairs_df['name_similarity'] = name_similarities\n",
    "candidate_pairs_df['description_similarity'] = description_similarities\n",
    "candidate_pairs_df['manufacturer_similarity'] = manufacturer_similarities\n",
    "\n",
    "candidate_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6981bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0 ----Precision:0.035; Recall: 0.0392; F1: 0.037\n",
      "Threshold: 0.1 ----Precision:0.035; Recall: 0.0392; F1: 0.037\n",
      "Threshold: 0.2 ----Precision:0.035; Recall: 0.0392; F1: 0.037\n",
      "Threshold: 0.3 ----Precision:0.035; Recall: 0.0392; F1: 0.037\n",
      "Threshold: 0.4 ----Precision:0.0648; Recall: 0.0385; F1: 0.0483\n",
      "Threshold: 0.5 ----Precision:0.0935; Recall: 0.0354; F1: 0.0513\n",
      "Threshold: 0.6 ----Precision:0.2529; Recall: 0.0331; F1: 0.0585\n",
      "Threshold: 0.7 ----Precision:0.3462; Recall: 0.0138; F1: 0.0266\n",
      "Threshold: 0.8 ----Precision:0.25; Recall: 0.0008; F1: 0.0015\n",
      "Threshold: 0.9 ----Precision:0.0; Recall: 0.0; F1: 0\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0, 1, 0.1)\n",
    "pred_pairs = set()\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_pairs = candidate_pairs_df[candidate_pairs_df['avg_similarity'] >= threshold]\n",
    "    pred_pairs = set(zip(filtered_pairs['amazon_id'], filtered_pairs['google_id']))\n",
    "    \n",
    "    true_positive_pairs = pred_pairs.intersection(ground_truth_pairs)\n",
    "    precision = len(true_positive_pairs) / len(filtered_pairs)\n",
    "    recall = len(true_positive_pairs) / len(ground_truth_pairs)\n",
    "    if (precision+recall)==0:\n",
    "        f1_score_alg=0\n",
    "    else:\n",
    "        f1_score_alg = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    print(f'Threshold: {round(threshold,1)} ----Precision:{round(precision,4)}; Recall: {round(recall,4)}; F1: {round(f1_score_alg,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d086ca5",
   "metadata": {},
   "source": [
    "**Threshold is 0.6, best f1 is 0.0585.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6362ae",
   "metadata": {},
   "source": [
    "## Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2190822",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "In this follow-up assignment, you will build upon the entity resolution work from HW5. This time, you will incorporate additional similarity metrics and use machine learning models.\n",
    "\n",
    "### Datasets:\n",
    "You will continue to use the datasets from HW5:\n",
    "- Amazon.csv\n",
    "- Google.csv\n",
    "- Amazon_GoogleProducts_perfectMapping.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb911c",
   "metadata": {},
   "source": [
    "### Question 1: More blocking keys \n",
    "**[10 points]** First, let’s repeat Question 3.2 and 3.3 in HW5, but using the other two blocking keys in Question 2 of HW5. What are their (threshold-optimized) F-measures and how do they compare to the answer in 3.2? Are the optimized thresholds different for each of the methods?\n",
    "\n",
    "**Please only consider blocking strategy 2 (Name Token Blocking). You do not have to consider Description Token Blocking in this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b75bc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pairs = set()\n",
    "\n",
    "for block in name_blocks_constrained_cleaned:\n",
    "    block_pairs = set(product([full_joined_df.iloc[i,0] for i in block if 3226 <= i <= 4589],[full_joined_df.iloc[i,0] for i in block if 0 <= i <= 3225]))\n",
    "    name_pairs.update(block_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dcb561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>google_id</th>\n",
       "      <th>amazon_name_tfidf</th>\n",
       "      <th>google_name_tfidf</th>\n",
       "      <th>amazon_description_tfidf</th>\n",
       "      <th>google_description_tfidf</th>\n",
       "      <th>amazon_manufacturer_tfidf</th>\n",
       "      <th>google_manufacturer_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00004vx3p</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1548...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000e65hki</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1608...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0001gu7di</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/2243...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0009yegcu</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1202...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b000he9psc</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/5046...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.07787552772534471, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000ozjtoo</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/7343...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b000ecqxjq</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1828...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b00004swln</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1290...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0006b6b1a</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1837...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b000ap41x2</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1140...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                                          google_id  \\\n",
       "0  b00004vx3p  http://www.google.com/base/feeds/snippets/1548...   \n",
       "1  b000e65hki  http://www.google.com/base/feeds/snippets/1608...   \n",
       "2  b0001gu7di  http://www.google.com/base/feeds/snippets/2243...   \n",
       "3  b0009yegcu  http://www.google.com/base/feeds/snippets/1202...   \n",
       "4  b000he9psc  http://www.google.com/base/feeds/snippets/5046...   \n",
       "5  b000ozjtoo  http://www.google.com/base/feeds/snippets/7343...   \n",
       "6  b000ecqxjq  http://www.google.com/base/feeds/snippets/1828...   \n",
       "7  b00004swln  http://www.google.com/base/feeds/snippets/1290...   \n",
       "8  b0006b6b1a  http://www.google.com/base/feeds/snippets/1837...   \n",
       "9  b000ap41x2  http://www.google.com/base/feeds/snippets/1140...   \n",
       "\n",
       "                                   amazon_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                   google_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            amazon_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.07787552772534471, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            google_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           amazon_manufacturer_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           google_manufacturer_tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_candidate_pairs = []\n",
    "\n",
    "for amazon_id, google_id in name_pairs:\n",
    "    amazon_line = pd.DataFrame(amazon[amazon['id']==amazon_id])\n",
    "    google_line = pd.DataFrame(google[google['id']==google_id])\n",
    "\n",
    "    pair_data = {\n",
    "        'amazon_id': amazon_line.iloc[0,0],\n",
    "        'google_id': google_line.iloc[0,0],\n",
    "        'amazon_name_tfidf': amazon_line.iloc[0,12],\n",
    "        'google_name_tfidf': google_line.iloc[0,12],\n",
    "        'amazon_description_tfidf': amazon_line.iloc[0,13],\n",
    "        'google_description_tfidf': google_line.iloc[0,13],\n",
    "        'amazon_manufacturer_tfidf': amazon_line.iloc[0,14],\n",
    "        'google_manufacturer_tfidf': google_line.iloc[0,14]\n",
    "    }\n",
    "\n",
    "    new_candidate_pairs.append(pair_data)\n",
    "\n",
    "new_candidate_pairs_df = pd.DataFrame(new_candidate_pairs)\n",
    "new_candidate_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb6a660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\云忆\\AppData\\Local\\Temp\\ipykernel_9332\\1853300151.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  manufacturer_sim = np.dot(manufacturer_vector_amazon, manufacturer_vector_google) / (\n",
      "C:\\Users\\云忆\\AppData\\Local\\Temp\\ipykernel_9332\\1853300151.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  description_sim = np.dot(description_vector_amazon, description_vector_google) / (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>google_id</th>\n",
       "      <th>amazon_name_tfidf</th>\n",
       "      <th>google_name_tfidf</th>\n",
       "      <th>amazon_description_tfidf</th>\n",
       "      <th>google_description_tfidf</th>\n",
       "      <th>amazon_manufacturer_tfidf</th>\n",
       "      <th>google_manufacturer_tfidf</th>\n",
       "      <th>avg_similarity</th>\n",
       "      <th>name_similarity</th>\n",
       "      <th>description_similarity</th>\n",
       "      <th>manufacturer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00004vx3p</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1548...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.089959</td>\n",
       "      <td>0.245919</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000e65hki</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1608...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.167237</td>\n",
       "      <td>0.329629</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0001gu7di</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/2243...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.083040</td>\n",
       "      <td>0.194663</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0009yegcu</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1202...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525485</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b000he9psc</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/5046...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.07787552772534471, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.048970</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000ozjtoo</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/7343...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.047906</td>\n",
       "      <td>0.138068</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b000ecqxjq</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1828...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>0.288220</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b00004swln</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1290...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.091819</td>\n",
       "      <td>0.152497</td>\n",
       "      <td>0.122961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0006b6b1a</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1837...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.624055</td>\n",
       "      <td>0.634602</td>\n",
       "      <td>0.237562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b000ap41x2</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1140...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                                          google_id  \\\n",
       "0  b00004vx3p  http://www.google.com/base/feeds/snippets/1548...   \n",
       "1  b000e65hki  http://www.google.com/base/feeds/snippets/1608...   \n",
       "2  b0001gu7di  http://www.google.com/base/feeds/snippets/2243...   \n",
       "3  b0009yegcu  http://www.google.com/base/feeds/snippets/1202...   \n",
       "4  b000he9psc  http://www.google.com/base/feeds/snippets/5046...   \n",
       "5  b000ozjtoo  http://www.google.com/base/feeds/snippets/7343...   \n",
       "6  b000ecqxjq  http://www.google.com/base/feeds/snippets/1828...   \n",
       "7  b00004swln  http://www.google.com/base/feeds/snippets/1290...   \n",
       "8  b0006b6b1a  http://www.google.com/base/feeds/snippets/1837...   \n",
       "9  b000ap41x2  http://www.google.com/base/feeds/snippets/1140...   \n",
       "\n",
       "                                   amazon_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                   google_name_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            amazon_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.07787552772534471, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                            google_description_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           amazon_manufacturer_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           google_manufacturer_tfidf  avg_similarity  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.089959   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.167237   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.083040   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.508495   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.048970   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.047906   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.137249   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.091819   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.624055   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        0.053589   \n",
       "\n",
       "   name_similarity  description_similarity  manufacturer_similarity  \n",
       "0         0.245919                0.023959                      0.0  \n",
       "1         0.329629                0.172081                      0.0  \n",
       "2         0.194663                0.054457                      0.0  \n",
       "3         1.000000                0.525485                      0.0  \n",
       "4         0.146909                0.000000                      0.0  \n",
       "5         0.138068                0.005650                      0.0  \n",
       "6         0.288220                0.123527                      0.0  \n",
       "7         0.152497                0.122961                      0.0  \n",
       "8         0.634602                0.237562                      1.0  \n",
       "9         0.160767                0.000000                      0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_similarities = []\n",
    "name_similarities = []\n",
    "description_similarities = []\n",
    "manufacturer_similarities = []\n",
    "\n",
    "for i in range(len(new_candidate_pairs_df)):\n",
    "    name_vector_amazon = new_candidate_pairs_df.iloc[i, 2]\n",
    "    name_vector_google = new_candidate_pairs_df.iloc[i, 3]\n",
    "\n",
    "    description_vector_amazon = new_candidate_pairs_df.iloc[i, 4]\n",
    "    description_vector_google = new_candidate_pairs_df.iloc[i, 5]\n",
    "\n",
    "    manufacturer_vector_amazon = new_candidate_pairs_df.iloc[i, 6]\n",
    "    manufacturer_vector_google = new_candidate_pairs_df.iloc[i, 7]\n",
    "\n",
    "    name_sim = np.dot(name_vector_amazon, name_vector_google) / (\n",
    "            norm(name_vector_amazon) * norm(name_vector_google))\n",
    "    \n",
    "    description_sim = np.dot(description_vector_amazon, description_vector_google) / (\n",
    "            norm(description_vector_amazon) * norm(description_vector_google))\n",
    "    \n",
    "    manufacturer_sim = np.dot(manufacturer_vector_amazon, manufacturer_vector_google) / (\n",
    "            norm(manufacturer_vector_amazon) * norm(manufacturer_vector_google))\n",
    "\n",
    "    name_sim = np.nan_to_num(name_sim, nan=0)\n",
    "    name_similarities.append(name_sim)\n",
    "\n",
    "    description_sim = np.nan_to_num(description_sim, nan=0)\n",
    "    description_similarities.append(description_sim)\n",
    "\n",
    "    manufacturer_sim = np.nan_to_num(manufacturer_sim, nan=0)\n",
    "    manufacturer_similarities.append(manufacturer_sim)\n",
    "\n",
    "    avg_similarity = np.mean([name_sim, description_sim, manufacturer_sim], axis=0)\n",
    "    avg_similarities.append(avg_similarity)\n",
    "\n",
    "new_candidate_pairs_df['avg_similarity'] = avg_similarities\n",
    "new_candidate_pairs_df['name_similarity'] = name_similarities\n",
    "new_candidate_pairs_df['description_similarity'] = description_similarities\n",
    "new_candidate_pairs_df['manufacturer_similarity'] = manufacturer_similarities\n",
    "\n",
    "new_candidate_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b7b3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0 ----Precision:0.0386; Recall: 0.9423; F1: 0.0742\n",
      "Threshold: 0.1 ----Precision:0.0979; Recall: 0.94; F1: 0.1773\n",
      "Threshold: 0.2 ----Precision:0.216; Recall: 0.8469; F1: 0.3442\n",
      "Threshold: 0.3 ----Precision:0.3189; Recall: 0.5492; F1: 0.4035\n",
      "Threshold: 0.4 ----Precision:0.3237; Recall: 0.2338; F1: 0.2715\n",
      "Threshold: 0.5 ----Precision:0.2952; Recall: 0.0892; F1: 0.137\n",
      "Threshold: 0.6 ----Precision:0.3533; Recall: 0.0454; F1: 0.0804\n",
      "Threshold: 0.7 ----Precision:0.4074; Recall: 0.0169; F1: 0.0325\n",
      "Threshold: 0.8 ----Precision:0.5556; Recall: 0.0038; F1: 0.0076\n",
      "Threshold: 0.9 ----Precision:0.25; Recall: 0.0008; F1: 0.0015\n",
      "Threshold: 1.0 ----Precision:0; Recall: 0.0; F1: 0\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_pairs = new_candidate_pairs_df[new_candidate_pairs_df['avg_similarity'] >= threshold]\n",
    "    pred_pairs = set(zip(filtered_pairs['amazon_id'], filtered_pairs['google_id']))\n",
    "    \n",
    "    true_positive_pairs = pred_pairs.intersection(ground_truth_pairs)\n",
    "    if len(filtered_pairs)>0:\n",
    "        precision = len(true_positive_pairs) / len(filtered_pairs)\n",
    "    else:\n",
    "        precision=0\n",
    "\n",
    "    recall = len(true_positive_pairs) / len(ground_truth_pairs)\n",
    "    if (precision+recall)==0:\n",
    "        f1_score_result=0\n",
    "    else:\n",
    "        f1_score_result = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    print(f'Threshold: {round(threshold,1)} ----Precision:{round(precision,4)}; Recall: {round(recall,4)}; F1: {round(f1_score_result,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480f787",
   "metadata": {},
   "source": [
    "**The best threshold is 0.3, best F1 is 0.4. The result is better than HW5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5f4b5",
   "metadata": {},
   "source": [
    "For the remainder of the questions below, assume the candidate set generated by the ***Name Token Blocking***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "459e3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_candidate_pairs_df = pd.merge(new_candidate_pairs_df, amazon, how='left', left_on='amazon_id', right_on='id')\n",
    "new_candidate_pairs_df = new_candidate_pairs_df[['amazon_id', 'google_id', 'avg_similarity', 'name_similarity', 'description_similarity','manufacturer_similarity','name', 'description', 'manufacturer', 'price']]\n",
    "new_candidate_pairs_df.columns = ['amazon_id', 'google_id', 'avg_similarity', 'name_similarity', 'description_similarity','manufacturer_similarity','amazon_name', 'amazon_description', 'amazon_manufacturer', 'amazon_price']\n",
    "\n",
    "new_candidate_pairs_df = pd.merge(new_candidate_pairs_df, google, how='left', left_on='google_id', right_on='id')\n",
    "new_candidate_pairs_df = new_candidate_pairs_df[['amazon_id', 'google_id', 'avg_similarity', 'name_similarity', 'description_similarity','manufacturer_similarity','amazon_name', 'amazon_description', 'amazon_manufacturer', 'amazon_price', 'name', 'description', 'manufacturer', 'price']]\n",
    "new_candidate_pairs_df.columns = ['amazon_id', 'google_id', 'avg_similarity', 'name_similarity', 'description_similarity','manufacturer_similarity','amazon_name', 'amazon_description', 'amazon_manufacturer', 'amazon_price', 'google_name', 'google_description', 'google_manufacturer', 'google_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae58aa1",
   "metadata": {},
   "source": [
    "### Question 2: More Similarity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b33a80",
   "metadata": {},
   "source": [
    "**2.1 [15 points]** We will now explore a different way of computing similarity between the two records in a candidate pair. Calculate the normalized Levenshtein similarity for each pair of fields in the candidate pair (hint: in class, we discussed a method for converting Levenshtein distance to normalized Levenshtein similarity, such that it lies in [0,1]). Create three more columns in the \"candidate_pairs\" DataFrame: 'name_lev', 'description_lev', 'manufacturer_lev‘. \n",
    "\n",
    "Print the first five rows of the new \"candidate_pairs\" DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cb279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_levenshtein(row):\n",
    "    name_distance = lev(row['amazon_name'], row['google_name'])\n",
    "    description_distance = lev(row['amazon_description'], row['google_description'])\n",
    "    manufacturer_distance = lev(row['amazon_manufacturer'], row['google_manufacturer'])\n",
    "\n",
    "    name_similarity = (1 - name_distance / max(len(row['amazon_name']), len(row['google_name']))) if max(len(row['amazon_name']), len(row['google_name'])) > 0 else 0\n",
    "    description_similarity = (1 - description_distance / max(len(row['amazon_description']), len(row['google_description']))) if max(len(row['amazon_description']), len(row['google_description'])) > 0 else 0\n",
    "    manufacturer_similarity = (1 - manufacturer_distance / max(len(row['amazon_manufacturer']), len(row['google_manufacturer']))) if max(len(row['amazon_manufacturer']), len(row['google_manufacturer'])) > 0 else 0\n",
    "\n",
    "    return pd.Series([name_distance, description_distance, manufacturer_distance, name_similarity, description_similarity, manufacturer_similarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "effbca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_candidate_pairs_df[['name_lev', 'description_lev', 'manufacturer_lev', 'name_lev_similarity', 'description_lev_similarity', 'manufacturer_lev_similarity']] = new_candidate_pairs_df.apply(calculate_levenshtein, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91014afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_id</th>\n",
       "      <th>google_id</th>\n",
       "      <th>avg_similarity</th>\n",
       "      <th>name_similarity</th>\n",
       "      <th>description_similarity</th>\n",
       "      <th>manufacturer_similarity</th>\n",
       "      <th>amazon_name</th>\n",
       "      <th>amazon_description</th>\n",
       "      <th>amazon_manufacturer</th>\n",
       "      <th>amazon_price</th>\n",
       "      <th>google_name</th>\n",
       "      <th>google_description</th>\n",
       "      <th>google_manufacturer</th>\n",
       "      <th>google_price</th>\n",
       "      <th>name_lev</th>\n",
       "      <th>description_lev</th>\n",
       "      <th>manufacturer_lev</th>\n",
       "      <th>name_lev_similarity</th>\n",
       "      <th>description_lev_similarity</th>\n",
       "      <th>manufacturer_lev_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00004vx3p</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1548...</td>\n",
       "      <td>0.089959</td>\n",
       "      <td>0.245919</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>easy drums (jewel case)</td>\n",
       "      <td>easy drums is an interactive guide that will s...</td>\n",
       "      <td>arcmedia</td>\n",
       "      <td>9.99</td>\n",
       "      <td>roxio(r) easy media creator(r) 9 suite</td>\n",
       "      <td>the roxio easy media creator 9 suite lets you ...</td>\n",
       "      <td></td>\n",
       "      <td>99.99</td>\n",
       "      <td>29.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.244353</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000e65hki</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1608...</td>\n",
       "      <td>0.167237</td>\n",
       "      <td>0.329629</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>punch! home design architectural series 4000 v10</td>\n",
       "      <td>punch! home design architectural series 4000 b...</td>\n",
       "      <td>punch! software</td>\n",
       "      <td>199.99</td>\n",
       "      <td>punch software 38100 - punch! super home suite...</td>\n",
       "      <td>punch software 38100 : the premium home design...</td>\n",
       "      <td></td>\n",
       "      <td>45.97</td>\n",
       "      <td>113.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.220430</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0001gu7di</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/2243...</td>\n",
       "      <td>0.083040</td>\n",
       "      <td>0.194663</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mavis beacon teaches typing deluxe 16</td>\n",
       "      <td>mavis beacon teaches typing 16 deluxe offers t...</td>\n",
       "      <td>broderbund</td>\n",
       "      <td>39.99</td>\n",
       "      <td>individual software prm-wn5 professor teaches ...</td>\n",
       "      <td>professor teaches windows xp prm-wn5 individua...</td>\n",
       "      <td>individual software</td>\n",
       "      <td>24.99</td>\n",
       "      <td>43.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0009yegcu</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1202...</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>instant architect design suite</td>\n",
       "      <td>instant architect design suite (win 98 me nt 2...</td>\n",
       "      <td>imsi design</td>\n",
       "      <td>29.99</td>\n",
       "      <td>instant architect design suite (00ids510cc)</td>\n",
       "      <td>instant architect design suite brand: imsi des...</td>\n",
       "      <td></td>\n",
       "      <td>28.79</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b000he9psc</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/5046...</td>\n",
       "      <td>0.048970</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the print shop 22 pro publisher deluxe sb cs b...</td>\n",
       "      <td>the print shop 22 pro publisher deluxe deliver...</td>\n",
       "      <td>encore software</td>\n",
       "      <td>99.95</td>\n",
       "      <td>encore software 11231 - hoyle bridge club sb c...</td>\n",
       "      <td>encore software 11231 : encore software hoyle ...</td>\n",
       "      <td></td>\n",
       "      <td>25.97</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.061093</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b000ozjtoo</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/7343...</td>\n",
       "      <td>0.047906</td>\n",
       "      <td>0.138068</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tlc arthur's kindergarten learning system 2008</td>\n",
       "      <td>tlc arthur's kindergarten learning system is d...</td>\n",
       "      <td>encore</td>\n",
       "      <td>19.99</td>\n",
       "      <td>berlitz french premier language learning</td>\n",
       "      <td>system requirements: macintosh os x 10.2.8 or ...</td>\n",
       "      <td></td>\n",
       "      <td>39.99</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.086739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b000ecqxjq</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1828...</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>0.288220</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sims 2 nightlife expansion pack</td>\n",
       "      <td>sims 2: nightlife takes your sim into the nigh...</td>\n",
       "      <td>aspyr media</td>\n",
       "      <td>34.99</td>\n",
       "      <td>sims 2 pets for mac</td>\n",
       "      <td>system requirements: requires the full version...</td>\n",
       "      <td></td>\n",
       "      <td>34.99</td>\n",
       "      <td>18.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.238397</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b00004swln</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1290...</td>\n",
       "      <td>0.091819</td>\n",
       "      <td>0.152497</td>\n",
       "      <td>0.122961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>vpn manager five to ten firebox</td>\n",
       "      <td>watchguard vpn manager provides centralized ma...</td>\n",
       "      <td>watchguard technologies inc</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>wg3605 watchguard mobile user vpn - complete p...</td>\n",
       "      <td>watchguard technologies wg3605 : usually ships...</td>\n",
       "      <td></td>\n",
       "      <td>290.68</td>\n",
       "      <td>71.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b0006b6b1a</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1837...</td>\n",
       "      <td>0.624055</td>\n",
       "      <td>0.634602</td>\n",
       "      <td>0.237562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>business plan writer deluxe 8.0 2005</td>\n",
       "      <td>business plan writer deluxe 8 helps you get yo...</td>\n",
       "      <td>nova development</td>\n",
       "      <td>99.99</td>\n",
       "      <td>nova development bsw business plan writer delu...</td>\n",
       "      <td>business plan writer deluxe 8.0 bsw nova devel...</td>\n",
       "      <td>nova development</td>\n",
       "      <td>94.99</td>\n",
       "      <td>26.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b000ap41x2</td>\n",
       "      <td>http://www.google.com/base/feeds/snippets/1140...</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rayman 10th anniversary collection</td>\n",
       "      <td>three critically acclaimed action-packed games...</td>\n",
       "      <td>ubi soft</td>\n",
       "      <td>19.99</td>\n",
       "      <td>git captain america: the complete collection d...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.99</td>\n",
       "      <td>35.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazon_id                                          google_id  \\\n",
       "0  b00004vx3p  http://www.google.com/base/feeds/snippets/1548...   \n",
       "1  b000e65hki  http://www.google.com/base/feeds/snippets/1608...   \n",
       "2  b0001gu7di  http://www.google.com/base/feeds/snippets/2243...   \n",
       "3  b0009yegcu  http://www.google.com/base/feeds/snippets/1202...   \n",
       "4  b000he9psc  http://www.google.com/base/feeds/snippets/5046...   \n",
       "5  b000ozjtoo  http://www.google.com/base/feeds/snippets/7343...   \n",
       "6  b000ecqxjq  http://www.google.com/base/feeds/snippets/1828...   \n",
       "7  b00004swln  http://www.google.com/base/feeds/snippets/1290...   \n",
       "8  b0006b6b1a  http://www.google.com/base/feeds/snippets/1837...   \n",
       "9  b000ap41x2  http://www.google.com/base/feeds/snippets/1140...   \n",
       "\n",
       "   avg_similarity  name_similarity  description_similarity  \\\n",
       "0        0.089959         0.245919                0.023959   \n",
       "1        0.167237         0.329629                0.172081   \n",
       "2        0.083040         0.194663                0.054457   \n",
       "3        0.508495         1.000000                0.525485   \n",
       "4        0.048970         0.146909                0.000000   \n",
       "5        0.047906         0.138068                0.005650   \n",
       "6        0.137249         0.288220                0.123527   \n",
       "7        0.091819         0.152497                0.122961   \n",
       "8        0.624055         0.634602                0.237562   \n",
       "9        0.053589         0.160767                0.000000   \n",
       "\n",
       "   manufacturer_similarity                                        amazon_name  \\\n",
       "0                      0.0                            easy drums (jewel case)   \n",
       "1                      0.0   punch! home design architectural series 4000 v10   \n",
       "2                      0.0              mavis beacon teaches typing deluxe 16   \n",
       "3                      0.0                     instant architect design suite   \n",
       "4                      0.0  the print shop 22 pro publisher deluxe sb cs b...   \n",
       "5                      0.0     tlc arthur's kindergarten learning system 2008   \n",
       "6                      0.0                    sims 2 nightlife expansion pack   \n",
       "7                      0.0                    vpn manager five to ten firebox   \n",
       "8                      1.0               business plan writer deluxe 8.0 2005   \n",
       "9                      0.0                 rayman 10th anniversary collection   \n",
       "\n",
       "                                  amazon_description  \\\n",
       "0  easy drums is an interactive guide that will s...   \n",
       "1  punch! home design architectural series 4000 b...   \n",
       "2  mavis beacon teaches typing 16 deluxe offers t...   \n",
       "3  instant architect design suite (win 98 me nt 2...   \n",
       "4  the print shop 22 pro publisher deluxe deliver...   \n",
       "5  tlc arthur's kindergarten learning system is d...   \n",
       "6  sims 2: nightlife takes your sim into the nigh...   \n",
       "7  watchguard vpn manager provides centralized ma...   \n",
       "8  business plan writer deluxe 8 helps you get yo...   \n",
       "9  three critically acclaimed action-packed games...   \n",
       "\n",
       "           amazon_manufacturer amazon_price  \\\n",
       "0                     arcmedia         9.99   \n",
       "1              punch! software       199.99   \n",
       "2                   broderbund        39.99   \n",
       "3                  imsi design        29.99   \n",
       "4              encore software        99.95   \n",
       "5                       encore        19.99   \n",
       "6                  aspyr media        34.99   \n",
       "7  watchguard technologies inc       1995.0   \n",
       "8             nova development        99.99   \n",
       "9                     ubi soft        19.99   \n",
       "\n",
       "                                         google_name  \\\n",
       "0             roxio(r) easy media creator(r) 9 suite   \n",
       "1  punch software 38100 - punch! super home suite...   \n",
       "2  individual software prm-wn5 professor teaches ...   \n",
       "3        instant architect design suite (00ids510cc)   \n",
       "4  encore software 11231 - hoyle bridge club sb c...   \n",
       "5           berlitz french premier language learning   \n",
       "6                                sims 2 pets for mac   \n",
       "7  wg3605 watchguard mobile user vpn - complete p...   \n",
       "8  nova development bsw business plan writer delu...   \n",
       "9  git captain america: the complete collection d...   \n",
       "\n",
       "                                  google_description  google_manufacturer  \\\n",
       "0  the roxio easy media creator 9 suite lets you ...                        \n",
       "1  punch software 38100 : the premium home design...                        \n",
       "2  professor teaches windows xp prm-wn5 individua...  individual software   \n",
       "3  instant architect design suite brand: imsi des...                        \n",
       "4  encore software 11231 : encore software hoyle ...                        \n",
       "5  system requirements: macintosh os x 10.2.8 or ...                        \n",
       "6  system requirements: requires the full version...                        \n",
       "7  watchguard technologies wg3605 : usually ships...                        \n",
       "8  business plan writer deluxe 8.0 bsw nova devel...     nova development   \n",
       "9                                                                           \n",
       "\n",
       "  google_price  name_lev  description_lev  manufacturer_lev  \\\n",
       "0        99.99      29.0            368.0               8.0   \n",
       "1        45.97     113.0            580.0              14.0   \n",
       "2        24.99      43.0            422.0              18.0   \n",
       "3        28.79      13.0             68.0              10.0   \n",
       "4        25.97      45.0           1168.0              14.0   \n",
       "5        39.99      37.0           2011.0               6.0   \n",
       "6        34.99      18.0            361.0              10.0   \n",
       "7       290.68      71.0            863.0              26.0   \n",
       "8        94.99      26.0            375.0               0.0   \n",
       "9        42.99      35.0             82.0               7.0   \n",
       "\n",
       "   name_lev_similarity  description_lev_similarity  \\\n",
       "0             0.236842                    0.244353   \n",
       "1             0.236486                    0.220430   \n",
       "2             0.232143                    0.096360   \n",
       "3             0.697674                    0.381818   \n",
       "4             0.328358                    0.061093   \n",
       "5             0.195652                    0.086739   \n",
       "6             0.419355                    0.238397   \n",
       "7             0.183908                    0.153091   \n",
       "8             0.500000                    0.115566   \n",
       "9             0.326923                    0.012048   \n",
       "\n",
       "   manufacturer_lev_similarity  \n",
       "0                     0.000000  \n",
       "1                     0.066667  \n",
       "2                     0.052632  \n",
       "3                     0.090909  \n",
       "4                     0.066667  \n",
       "5                     0.000000  \n",
       "6                     0.090909  \n",
       "7                     0.037037  \n",
       "8                     1.000000  \n",
       "9                     0.125000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_candidate_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18a1c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31741 entries, 0 to 31740\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   amazon_id                    31741 non-null  object \n",
      " 1   google_id                    31741 non-null  object \n",
      " 2   avg_similarity               31741 non-null  float64\n",
      " 3   name_similarity              31741 non-null  float64\n",
      " 4   description_similarity       31741 non-null  float64\n",
      " 5   manufacturer_similarity      31741 non-null  float64\n",
      " 6   amazon_name                  31741 non-null  object \n",
      " 7   amazon_description           31741 non-null  object \n",
      " 8   amazon_manufacturer          31741 non-null  object \n",
      " 9   amazon_price                 31741 non-null  object \n",
      " 10  google_name                  31741 non-null  object \n",
      " 11  google_description           31741 non-null  object \n",
      " 12  google_manufacturer          31741 non-null  object \n",
      " 13  google_price                 31741 non-null  object \n",
      " 14  name_lev                     31741 non-null  float64\n",
      " 15  description_lev              31741 non-null  float64\n",
      " 16  manufacturer_lev             31741 non-null  float64\n",
      " 17  name_lev_similarity          31741 non-null  float64\n",
      " 18  description_lev_similarity   31741 non-null  float64\n",
      " 19  manufacturer_lev_similarity  31741 non-null  float64\n",
      "dtypes: float64(10), object(10)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "new_candidate_pairs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d9f63",
   "metadata": {},
   "source": [
    "\n",
    "**2.2 [15 points]** Refer to the `Amazon_GoogleProducts_perfectMapping.csv` file for the actual matches. Create a new column named 'match' in your \"candidate_pairs\" DataFrame. If a pair of records (in the candidate set) corresponds to a match i.e., is in the perfectMapping file, label it as 'yes' in the 'match' column. Otherwise, label it as 'no.' Note that, by design, most pairs will actually be no! Furthermore, not every pair in the perfectMapping will be included here. What is the number of ‘false negatives’ that are not included in your dataset? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34f6cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FN:  75\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(new_candidate_pairs_df, perfect_match, how='left', left_on=['amazon_id', 'google_id'], right_on=['idAmazon', 'idGoogleBase'])\n",
    "new_candidate_pairs_df['match'] = np.where(merged_df['idAmazon'].notnull(), 1, 0)\n",
    "false_negatives = len(perfect_match) - len(new_candidate_pairs_df[new_candidate_pairs_df['match']==1])\n",
    "\n",
    "print(\"Number of FN: \", false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e67a1d",
   "metadata": {},
   "source": [
    "### Question 3: Feature Engineering for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d028336",
   "metadata": {},
   "source": [
    "**[10 points]** Prepare your feature matrix (X) and labels (y) for the machine learning model. \n",
    "\n",
    "Each row in X should correspond to a pair of records and contain the \n",
    "\n",
    "(i) three Levenshtein features calculated in Question 1; <br>\n",
    "(ii) the three cosine similarity features you had computed earlier in HW5; and each entry in y should be the label indicating whether the pair of records is a match. Below is a feature set for each pair, including:\n",
    "\n",
    "* name_lev: Levenshtein distance between product names.\n",
    "* description_lev: Levenshtein distance between product descriptions.\n",
    "* manufacturer_lev: Levenshtein distance between manufacturer names.\n",
    "* name_tfidf_sim: Cosine similarity of TF-IDF vectors for product names.\n",
    "* description_tfidf_sim: Cosine similarity of TF-IDF vectors for product descriptions.\n",
    "* manufacturer_tfidf_sim: Cosine similarity of TF-IDF vectors for manufacturer names.\n",
    "\n",
    "Print the first five vectors of matrix (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a6b860f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_similarity</th>\n",
       "      <th>description_similarity</th>\n",
       "      <th>manufacturer_similarity</th>\n",
       "      <th>name_lev_similarity</th>\n",
       "      <th>description_lev_similarity</th>\n",
       "      <th>manufacturer_lev_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245919</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.244353</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329629</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.220430</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194663</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.061093</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_similarity  description_similarity  manufacturer_similarity  \\\n",
       "0         0.245919                0.023959                      0.0   \n",
       "1         0.329629                0.172081                      0.0   \n",
       "2         0.194663                0.054457                      0.0   \n",
       "3         1.000000                0.525485                      0.0   \n",
       "4         0.146909                0.000000                      0.0   \n",
       "\n",
       "   name_lev_similarity  description_lev_similarity  \\\n",
       "0             0.236842                    0.244353   \n",
       "1             0.236486                    0.220430   \n",
       "2             0.232143                    0.096360   \n",
       "3             0.697674                    0.381818   \n",
       "4             0.328358                    0.061093   \n",
       "\n",
       "   manufacturer_lev_similarity  \n",
       "0                     0.000000  \n",
       "1                     0.066667  \n",
       "2                     0.052632  \n",
       "3                     0.090909  \n",
       "4                     0.066667  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = new_candidate_pairs_df[['name_similarity', 'description_similarity','manufacturer_similarity','name_lev_similarity', 'description_lev_similarity', 'manufacturer_lev_similarity']]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74afd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=new_candidate_pairs_df['match']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfcd85",
   "metadata": {},
   "source": [
    "### Question 4: Machine Learning for Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644dafd",
   "metadata": {},
   "source": [
    "**4.1 [15 points]** : Randomly partition the matrix into a training set containing 80% of duplicates and non-duplicates, and a test set containing the rest. The training set must remain fixed for the experiments in 3.2. In running your code, verify that approximately 80% of the matches and non-matches in your original dataset compiled at the end of Q1 are in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6108e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a5dde54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999747960051669"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)/len(new_candidate_pairs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f4d74",
   "metadata": {},
   "source": [
    "**4.2 [15 points]** : Select any three different machine learning models from the sklearn package (e.g., a decision tree-based model, a logistic regression model…) . Train each model using the feature set prepared in Question 2. You will end up with a total of three trained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc8313d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=2)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=2)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=2)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d355fa6",
   "metadata": {},
   "source": [
    "**4.3 [10 points]** : Provide a table below where, for each method, you are providing the AUC, precision, recall, F-measure and accuracy. Based on the numbers, which of these metrics might be problematic for evaluating ER? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "251e70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_precision = precision_score(y_test, dt_predictions)\n",
    "dt_recall = recall_score(y_test, dt_predictions)\n",
    "dt_f1 = f1_score(y_test, dt_predictions)\n",
    "dt_auc = roc_auc_score(y_test, dt_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "rf_f1 = f1_score(y_test, rf_predictions)\n",
    "rf_auc = roc_auc_score(y_test, rf_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "gb_precision = precision_score(y_test, gb_predictions)\n",
    "gb_recall = recall_score(y_test, gb_predictions)\n",
    "gb_f1 = f1_score(y_test, gb_predictions)\n",
    "gb_auc = roc_auc_score(y_test, gb_predictions)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5132ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Method       AUC  Precision    Recall  F-measure  Accuracy\n",
      "0   Decision Tree  0.681836   0.392562  0.387755   0.390144  0.953221\n",
      "1   Random Forest  0.675742   0.651852  0.359184   0.463158  0.967869\n",
      "2  Gradient Boost  0.623336   0.613861  0.253061   0.358382  0.965034\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = {\n",
    "    'Method': ['Decision Tree', 'Random Forest', 'Gradient Boost'],\n",
    "    'AUC': [dt_auc, rf_auc, gb_auc],\n",
    "    'Precision': [dt_precision, rf_precision, gb_precision],\n",
    "    'Recall': [dt_recall, rf_recall, gb_recall],\n",
    "    'F-measure': [dt_f1, rf_f1, gb_f1],\n",
    "    'Accuracy': [dt_accuracy, rf_accuracy, gb_accuracy]\n",
    "}\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_data)\n",
    "\n",
    "print(evaluation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae91714",
   "metadata": {},
   "source": [
    "I think just using precision or recall will cause problems. Because the dataset is very imbalance, just using one of them can not provide enough evaluating information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccea153",
   "metadata": {},
   "source": [
    "**4.4 [10 points]** : Using paired t-tests, can you indicate which (if any) of the three models is significantly better than each of the other two? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3c43f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value (1_2): 0.85193\n",
      "p-value (1_3): 0.51022\n",
      "p-value (2_3): 0.01896\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value_1_2 = ttest_rel(evaluation_df.iloc[0,:].to_list()[1:], evaluation_df.iloc[1,:].to_list()[1:], alternative='greater')\n",
    "t_statistic, p_value_1_3 = ttest_rel(evaluation_df.iloc[0,:].to_list()[1:], evaluation_df.iloc[2,:].to_list()[1:], alternative='greater')\n",
    "t_statistic, p_value_2_3 = ttest_rel(evaluation_df.iloc[1,:].to_list()[1:], evaluation_df.iloc[2,:].to_list()[1:], alternative='greater')\n",
    "\n",
    "print(\"p-value (1_2):\", round(p_value_1_2,5))\n",
    "print(\"p-value (1_3):\", round(p_value_1_3,5))\n",
    "print(\"p-value (2_3):\", round(p_value_2_3,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8ff18",
   "metadata": {},
   "source": [
    " Based on the evaluation metrics, Random Forest model is significantly better than others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
